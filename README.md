# DataMind-LSTM â€” GÃ¼ncel Proje Ã–zeti ve Ã‡alÄ±ÅŸtÄ±rma KÄ±lavuzu

Bu dÃ¶kÃ¼man projeyi mevcut Ã§alÄ±ÅŸma durumuna gÃ¶re baÅŸtan sona aÃ§Ä±klar; nasÄ±l kurup Ã§alÄ±ÅŸtÄ±racaÄŸÄ±nÄ±z, hangi Ã§Ä±ktÄ±larÄ± bekleyeceÄŸiniz, bilinen kÄ±sÄ±tlar ve Ã¶neriler burada yer almaktadÄ±r.

**KÄ±sa Ã–zet:** proje veri Ã¶n iÅŸleme, gÃ¶rselleÅŸtirme ve modelleme (Geleneksel ML + LSTM ve Bidirectional LSTM kesin olarak dahil) adÄ±mlarÄ±nÄ± iÃ§erir. Veri Ã¶n iÅŸleme baÅŸarÄ±yla Ã§alÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ, iÅŸlenmiÅŸ veriler `results/processed_data.csv` olarak kaydedildi ve birÃ§ok gÃ¶rsel Ã¼retildi. Model eÄŸitimi (tam pipeline) istenirse baÅŸlatÄ±labilir fakat LSTM/hiperparam optimizasyon aÄŸÄ±r ve zaman alÄ±cÄ± olabilir.

**Ã–nemli dosyalar:** `data_preprocessing.py`, `modeling.py`, `evaluation.py`, `main.py`, `requirements.txt` ve `results/` klasÃ¶rÃ¼.

**Not:** README gÃ¼ncellemesi sÄ±rasÄ±nda `data_preprocessing.py` iÃ§inde iki deÄŸiÅŸiklik yapÄ±ldÄ±:
- `create_train_test_split()` fonksiyonuna: sÄ±nÄ±f baÅŸÄ±na Ã¶rnek sayÄ±sÄ± Ã§ok azsa `stratify=None` kullanacak gÃ¼venli fallback eklendi.
- `create_visualizations()` iÃ§inde `killer_status` grafiÄŸi iyileÅŸtirildi ve `results/killer_status_distribution_improved.png` olarak kaydediliyor (kÃ¼Ã§Ã¼k kategoriler "DiÄŸer" altÄ±nda toplanÄ±yor, yatay bar, adet ve yÃ¼zde etiketleri).

**Dosya yollarÄ± (Ã¶nemli):**
- Ä°ÅŸlenmiÅŸ veri: `results/processed_data.csv`
- TÃ¼m gÃ¶rseller: `results/*.png` (Ã¶r. `correlation_matrix.png`, `age_distribution.png`, `killer_status_distribution_improved.png`)
- Log (konsol Ã§Ä±ktÄ±sÄ±): `run_output.log`
- Modeller (eÄŸitildiÄŸinde): `results/models/`

**Ä°Ã§indekiler:**
- **Kurulum**
- **HÄ±zlÄ± BaÅŸlangÄ±Ã§ (preprocessing / full run / baseline)**
- **Model detaylarÄ± (Ã¶zellikle LSTM & Bidirectional LSTM)**
- **Mevcut durum, bilinen sorunlar ve Ã¶neriler**
- **Sonraki adÄ±mlar / Ã¶neriler**

---

**Kurulum**

- Python 3.9+ (3.11 ile test edildi) Ã¶nerilir.
- Gerekli paketler `requirements.txt` iÃ§inde listeli. Kurmak iÃ§in PowerShell'de:

```powershell
python -m pip install -r "c:\Users\hilal\Desktop\DataMind-LSTM\requirements.txt"
```

Not: `tensorflow` gibi paketler sistemde bÃ¼yÃ¼k yer kaplar ve yÃ¼kleme/ilk import sÄ±rasÄ±nda zaman alabilir.

---

**HÄ±zlÄ± BaÅŸlangÄ±Ã§ - Ã–rnek Komutlar**

- Sadece veri Ã¶n iÅŸlemeyi Ã§alÄ±ÅŸtÄ±r (hÄ±zlÄ± smoke-test):

```powershell

$env:PYTHONIOENCODING='utf-8'; python -c "from data_preprocessing import main; main()"
```

- Tam pipeline (tÃ¼m adÄ±mlar: Ã¶n iÅŸleme -> geleneksel modeller -> hiperparam optimizasyon -> LSTM & BiLSTM -> deÄŸerlendirme -> rapor). UyarÄ±: LSTM ve RandomSearchCV aÄŸÄ±rdÄ±r.

```powershell
$env:PYTHONIOENCODING='utf-8'; python "c:\Users\hilal\Desktop\DataMind-LSTM\main.py"
```

Bu komut Ã§Ä±ktÄ±sÄ±nÄ± dosyaya kaydetmek istersen (Ã¶nemli loglar iÃ§in):

```powershell
$env:PYTHONIOENCODING='utf-8'; python "c:\Users\hilal\Desktop\DataMind-LSTM\main.py" 2>&1 | Tee-Object "c:\Users\hilal\Desktop\DataMind-LSTM\full_run_raw.log"; Get-Content "c:\Users\hilal\Desktop\DataMind-LSTM\full_run_raw.log" | Out-File "c:\Users\hilal\Desktop\DataMind-LSTM\full_run.log" -Encoding utf8
```

- HÄ±zlÄ± baseline: sadece iÅŸlenmiÅŸ veriyi kullanÄ±p RandomForest ile tek adÄ±mlÄ±k bir baseline Ã§alÄ±ÅŸtÄ±rmak istersen (Ã¶rnek):

```powershell
$env:PYTHONIOENCODING='utf-8'; python - <<'PY'
from data_preprocessing import main as preprocess_main
from modeling import ModelTrainer
res = preprocess_main()
trainer = ModelTrainer()
trainer.train_traditional_models(res['X_train'], res['X_val'], res['y_train'], res['y_val'])
PY
```

---

**Model DetaylarÄ± (Ã¶zellikle LSTM & Bidirectional LSTM)**

- Geleneksel modeller: `Logistic Regression`, `Random Forest`, `SVM` â€” bunlar `modeling.py` iÃ§indeki `train_traditional_models()` fonksiyonunda hazÄ±rlanÄ±r.
- Hiperparametre optimizasyonu: `RandomizedSearchCV` ile Random Forest iÃ§in uygulanÄ±r (`hyperparameter_optimization()` iÃ§inde).
- LSTM ve Bidirectional LSTM: kesinlikle projeye dahil edilmiÅŸtir (istenildiÄŸi gibi). Ã–zellikler:
  - Veri tabanlÄ± LSTM yaklaÅŸÄ±mÄ±: tabular veride her Ã¶rnek tek bir timestep olarak ele alÄ±nÄ±yor (shape â†’ (samples, 1, features)). Bu nedenle LSTM, zaman serisi dÄ±ÅŸÄ± tabular veride kullanÄ±lacaksa dikkatli yorumlanmalÄ±dÄ±r.
  - YapÄ± (Ã¶zet): iki katmanlÄ± LSTM (128 -> 64), Dropout katmanlarÄ±, Dense katman ve softmax Ã§Ä±kÄ±ÅŸ.
  - KayÄ±t: eÄŸitim geÃ§miÅŸleri ve model aÄŸÄ±rlÄ±klarÄ± `results/models/` iÃ§ine kaydedilir (Keras `.h5`).

Ã–nemli: LSTM/BiLSTM eÄŸitimi iÃ§in `n_classes` Ã§ok bÃ¼yÃ¼kse (burada `killer_status` iÃ§in 51 sÄ±nÄ±f) one-hot encoding ve softmax Ã§Ä±ktÄ±sÄ± zorlaÅŸÄ±r; sÄ±nÄ±f sayÄ±sÄ±nÄ± dÃ¼ÅŸÃ¼rmeyi veya problem tanÄ±mÄ±nÄ± deÄŸiÅŸtirmeyi dÃ¼ÅŸÃ¼nÃ¼n.

---

**Mevcut Durum â€” Ã–zet (2025-11-26)**

- Veri Ã¶n iÅŸleme: baÅŸarÄ±yla tamamlandÄ±. Ä°ÅŸlenmiÅŸ veri: `results/processed_data.csv` (â‰ˆ7169 satÄ±r).
- GÃ¶rselleÅŸtirmeler Ã¼retildi: `results/` iÃ§ine kaydedildi. `killer_status` gÃ¶rseli iyileÅŸtirildi ve `results/killer_status_distribution_improved.png` adÄ±yla kaydedildi.
- `run_output.log` iÃ§inde veri Ã¶n iÅŸleme Ã§Ä±ktÄ±sÄ± kaydedildi (terminal Ã§Ä±ktÄ±larÄ±). EÄŸer tam pipeline Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ysa `full_run.log` veya `full_run_raw.log` dosyalarÄ±nÄ± kontrol edin.
- Model eÄŸitimi: henÃ¼z tam pipeline (tÃ¼m modeller + LSTM) otomatik olarak Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ysa sonuÃ§lar `results/model_comparison.csv`, `results/evaluation_metrics.csv` gibi dosyalarda bulunur; aksi takdirde modelleri Ã§alÄ±ÅŸtÄ±rmak iÃ§in `main.py` baÅŸlatÄ±lmalÄ±dÄ±r.

---

**Bilinen Sorunlar / UyarÄ±lar**

- SÄ±nÄ±f dengesizliÄŸi: `killer_status` hedefi yÃ¼ksek kardinalitelidir (51 sÄ±nÄ±f). BazÄ± sÄ±nÄ±flarda Ã§ok az Ã¶rnek (1-2) mevcut. Bu, stratify ile split hatalarÄ±na ve dÃ¼ÅŸÃ¼k model gÃ¼venilirliÄŸine yol aÃ§ar. Bu yÃ¼zden `create_train_test_split()` iÃ§ine bir fallback (stratify=None) eklendi. Ancak stratify kapatÄ±lmasÄ± dengesiz daÄŸÄ±lÄ±mlara neden olabilir â€” Ã¶neriler aÅŸaÄŸÄ±da.
- Multi-label benzeri girdiler: bazÄ± `killer_status` kayÄ±tlarÄ±nda birden fazla etiket ("Tutuklu, AranÄ±yor") veya karÄ±ÅŸÄ±k format var. Mevcut pipeline tek-etiket (`LabelEncoder`) varsayar. EÄŸer bu gerÃ§ekten multi-label ise, etiketleme stratejisi deÄŸiÅŸmeli.
- LSTM kullanÄ±mÄ±: veri tabanlÄ± tek-timestep yaklaÅŸÄ±mla LSTM kullanmak mÃ¼mkÃ¼ndÃ¼r ancak genellikle tablo veride LSTM avantajÄ± sÄ±nÄ±rlÄ±dÄ±r. LSTM/BiLSTM yine de mevcut ve Ã§alÄ±ÅŸtÄ±rÄ±labilir; sonuÃ§larÄ± dikkatle yorumlayÄ±n.
- Zaman ve kaynak: LSTM eÄŸitimi ve RandomizedSearchCV CPU Ã¼zerinde Ã§ok uzun sÃ¼rebilir; mÃ¼mkÃ¼nse GPU (CUDA) kullanÄ±n.

---

**Ã–neriler / Next Steps**

1. SÄ±nÄ±f azaltma veya yeniden daÄŸÄ±tma:
    - Nadir sÄ±nÄ±flarÄ± `DiÄŸer` olarak birleÅŸtirin veya yalnÄ±zca en sÄ±k gÃ¶rÃ¼len N sÄ±nÄ±fa odaklanÄ±n.
    - Alternatif: sÄ±nÄ±f aÄŸÄ±rlÄ±ÄŸÄ± (`class_weight`) veya oversampling (SMOTE vb.) uygulayÄ±n.
2. Multi-label kontrolÃ¼:
    - `killer_status` iÃ§indeki birden fazla etiket varsa temizleyin veya multi-label pipeline uygulayÄ±n.
3. Baseline deÄŸerlendirmesi:
    - Ã–nce hÄ±zlÄ± bir RandomForest baseline Ã§alÄ±ÅŸtÄ±rÄ±p `macro-F1` ve per-class rapor alÄ±n.
4. Tekrarlanabilirlik:
    - Seed ayarlarÄ±nÄ± (`numpy.random.seed`, `random.seed`, `tensorflow.random.set_seed`) sabitleyin ve kullanÄ±lan encoder/Scaler nesnelerini diske kaydedin.
5. GPU kullanÄ±mÄ±:
    - EÄŸer GPU varsa TensorFlow GPU sÃ¼rÃ¼mÃ¼nÃ¼ ve CUDA uyumunu kurun; LSTM eÄŸitim sÃ¼resini Ã¶nemli Ã¶lÃ§Ã¼de azaltÄ±r.

---

**HÄ±zlÄ± Referans â€” Ã–nemli Komutlar (PowerShell)**

- Paketleri yÃ¼kle:

```powershell
python -m pip install -r "c:\Users\hilal\Desktop\DataMind-LSTM\requirements.txt"
```

- Sadece veri Ã¶n iÅŸleme (log terminalde gÃ¶sterilir):

```powershell
$env:PYTHONIOENCODING='utf-8'; python -c "from data_preprocessing import main; main()"
```

- Tam pipeline (uzun, LSTM dahil):

```powershell
$env:PYTHONIOENCODING='utf-8'; python "c:\Users\hilal\Desktop\DataMind-LSTM\main.py"
```

- Tam pipeline Ã§Ä±ktÄ±sÄ±nÄ± log dosyasÄ±na kaydet (UTF-8):

```powershell
$env:PYTHONIOENCODING='utf-8'; python "c:\Users\hilal\Desktop\DataMind-LSTM\main.py" 2>&1 | Tee-Object "c:\Users\hilal\Desktop\DataMind-LSTM\full_run_raw.log"; Get-Content "c:\Users\hilal\Desktop\DataMind-LSTM\full_run_raw.log" | Out-File "c:\Users\hilal\Desktop\DataMind-LSTM\full_run.log" -Encoding utf8
```

- Sadece hÄ±zlÄ± baseline (RandomForest) Ã§alÄ±ÅŸtÄ±rma Ã¶rneÄŸi:

```powershell
$env:PYTHONIOENCODING='utf-8'; python - <<'PY'
from data_preprocessing import main as preprocess_main
from modeling import ModelTrainer
res = preprocess_main()
trainer = ModelTrainer()
trainer.train_traditional_models(res['X_train'], res['X_val'], res['y_train'], res['y_val'])
PY
```

---

**Sorular / YardÄ±m**

- Ä°stersen ÅŸu adÄ±mlardan baÅŸlayabilirim:
  - (A) Hemen tam pipeline'Ä± Ã§alÄ±ÅŸtÄ±rÄ±p sonuÃ§larÄ± `results/` iÃ§ine kaydetmemi ister misin? (uzun sÃ¼rer)
  - (B) Ã–nce `killer_status` sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± birlikte inceleyip nasÄ±l gruplandÄ±racaÄŸÄ±mÄ±za karar verelim; sonra baseline ve LSTM adÄ±mlarÄ±na geÃ§elim. (Ã¶nerilen)
  - (C) Hemen hÄ±zlÄ± RandomForest baseline Ã§alÄ±ÅŸtÄ±rÄ±p macro-F1, per-class raporu hazÄ±rlayayÄ±m.

LÃ¼tfen hangi adÄ±mÄ± istediÄŸini sÃ¶yle; ben seÃ§imine gÃ¶re devam edip loglarÄ±, grafikleri ve Ã¶nerileri teslim edeceÄŸim.

#### 2.1.2. Random Forest

**AmaÃ§**: Ensemble yÃ¶ntemi ile gÃ¼Ã§lÃ¼ tahmin yapmak.

**Ã–zellikler**:
- N_estimators: 100
- Random state: 42
- Parallel processing (n_jobs=-1)

**KullanÄ±m AlanÄ±**: KarmaÅŸÄ±k iliÅŸkileri yakalayan, robust model.

**Kod Konumu**: `modeling.py` â†’ `train_traditional_models()` metodu

**DeÄŸerlendirme Metrikleri**:
- Accuracy
- F1-Score (weighted)

---

#### 2.1.3. Support Vector Machine (SVM)

**AmaÃ§**: Kernel trick ile non-linear sÄ±nÄ±flandÄ±rma yapmak.

**Ã–zellikler**:
- Kernel: RBF (Radial Basis Function)
- Probability: True (olasÄ±lÄ±k tahminleri iÃ§in)
- Sample size: 5000 (bÃ¼yÃ¼k veri setleri iÃ§in optimizasyon)

**Not**: BÃ¼yÃ¼k veri setleri iÃ§in yavaÅŸ olduÄŸundan Ã¶rneklem kullanÄ±lmÄ±ÅŸtÄ±r.

**Kod Konumu**: `modeling.py` â†’ `train_traditional_models()` metodu

**DeÄŸerlendirme Metrikleri**:
- Accuracy
- F1-Score (weighted)

---

### 2.2. Derin Ã–ÄŸrenme Modelleri

#### 2.2.1. LSTM (Long Short-Term Memory)

**AmaÃ§**: Zaman serisi ve sequence verileri iÃ§in derin Ã¶ÄŸrenme modeli.

**Model Mimarisi**:
```
Input Layer (Sequence)
    â†“
LSTM Layer 1 (128 units, return_sequences=True)
    â†“
Dropout (0.3)
    â†“
LSTM Layer 2 (64 units, return_sequences=False)
    â†“
Dropout (0.3)
    â†“
Dense Layer (32 units, ReLU)
    â†“
Dropout (0.2)
    â†“
Output Layer (n_classes, Softmax)
```

**Hiperparametreler**:
- Sequence Length: 10
- Learning Rate: 0.001
- Optimizer: Adam
- Loss: Categorical Crossentropy
- Epochs: 50
- Batch Size: 32

**Callbacks**:
- **Early Stopping**: Validation loss'u izleyerek overfitting'i Ã¶nler (patience=10)
- **ReduceLROnPlateau**: Learning rate'i dinamik olarak azaltÄ±r

**Kod Konumu**: `modeling.py` â†’ `train_lstm_model()` metodu

**Ã‡Ä±ktÄ±**:
- EÄŸitilmiÅŸ model
- EÄŸitim geÃ§miÅŸi (history)
- `results/LSTM_training_history.png`: EÄŸitim grafikleri

---

#### 2.2.2. Bidirectional LSTM

**AmaÃ§**: GeÃ§miÅŸ ve gelecek bilgilerini birlikte kullanan geliÅŸmiÅŸ LSTM modeli.

**Model Mimarisi**:
```
Input Layer (Sequence)
    â†“
Bidirectional LSTM Layer 1 (128 units, return_sequences=True)
    â†“
Dropout (0.3)
    â†“
Bidirectional LSTM Layer 2 (64 units, return_sequences=False)
    â†“
Dropout (0.3)
    â†“
Dense Layer (32 units, ReLU)
    â†“
Dropout (0.2)
    â†“
Output Layer (n_classes, Softmax)
```

**Avantajlar**:
- Ä°leri ve geri yÃ¶nlÃ¼ bilgi akÄ±ÅŸÄ±
- Daha iyi Ã¶zellik Ã¶ÄŸrenme
- Genellikle tek yÃ¶nlÃ¼ LSTM'den daha iyi performans

**Hiperparametreler**: LSTM ile aynÄ±

**Kod Konumu**: `modeling.py` â†’ `train_bidirectional_lstm_model()` metodu

**Ã‡Ä±ktÄ±**:
- EÄŸitilmiÅŸ model
- EÄŸitim geÃ§miÅŸi
- `results/Bidirectional_LSTM_training_history.png`: EÄŸitim grafikleri

---

### 2.3. Hiperparametre Optimizasyonu

**AmaÃ§**: En iyi model performansÄ±nÄ± bulmak iÃ§in hiperparametreleri optimize etmek.

**YÃ¶ntem**: RandomizedSearchCV

**Model**: Random Forest

**Optimize Edilen Hiperparametreler**:

| Parametre | DeÄŸerler |
|-----------|----------|
| `n_estimators` | [50, 100, 200] |
| `max_depth` | [10, 20, 30, None] |
| `min_samples_split` | [2, 5, 10] |
| `min_samples_leaf` | [1, 2, 4] |
| `max_features` | ['sqrt', 'log2'] |

**Arama Stratejisi**:
- Iterations: 20
- Cross-Validation: 3-fold
- Scoring: F1-Score (weighted)
- Random State: 42

**Ä°ÅŸlemler**:
1. Parametre grid'inin tanÄ±mlanmasÄ±
2. RandomizedSearchCV ile arama
3. En iyi parametrelerin bulunmasÄ±
4. En iyi modelin eÄŸitilmesi ve deÄŸerlendirilmesi

**Kod Konumu**: `modeling.py` â†’ `hyperparameter_optimization()` metodu

**Ã‡Ä±ktÄ±**:
- En iyi parametreler
- Optimize edilmiÅŸ model
- Performans metrikleri

---

### 2.4. Model KarÅŸÄ±laÅŸtÄ±rmasÄ±

**AmaÃ§**: TÃ¼m modellerin performanslarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rmak.

**KarÅŸÄ±laÅŸtÄ±rÄ±lan Modeller**:
1. Logistic Regression
2. Random Forest
3. SVM
4. Random Forest (Optimized)
5. LSTM
6. Bidirectional LSTM

**KarÅŸÄ±laÅŸtÄ±rma Metrikleri**:
- **Accuracy**: DoÄŸru tahmin yÃ¼zdesi
- **F1-Score**: Precision ve Recall'un harmonik ortalamasÄ± (weighted)

**Ä°ÅŸlemler**:
1. TÃ¼m modellerin validation seti Ã¼zerinde deÄŸerlendirilmesi
2. Metriklerin toplanmasÄ±
3. KarÅŸÄ±laÅŸtÄ±rma tablosunun oluÅŸturulmasÄ±
4. GÃ¶rselleÅŸtirme (bar charts)
5. CSV olarak kaydetme

**Kod Konumu**: `modeling.py` â†’ `compare_models()` metodu

**Ã‡Ä±ktÄ±**:
- `results/model_comparison.png`: GÃ¶rsel karÅŸÄ±laÅŸtÄ±rma
- `results/model_comparison.csv`: DetaylÄ± sonuÃ§lar

---

## ğŸš€ KullanÄ±m

### YÃ¶ntem 1: TÃ¼m Ä°ÅŸlemleri Tek Seferde Ã‡alÄ±ÅŸtÄ±rma (Ã–nerilen)

```bash
python main.py
```

Bu komut tÃ¼m iÅŸlemleri sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±r:
1. Veri Ã¶n iÅŸleme
2. Modelleme
3. DeÄŸerlendirme (confusion matrix, metrikler, overfitting analizi)
4. Rapor oluÅŸturma

### YÃ¶ntem 2: AdÄ±m AdÄ±m Ã‡alÄ±ÅŸtÄ±rma

#### AdÄ±m 1: Veri Ã–n Ä°ÅŸleme

```bash
python data_preprocessing.py
```

Bu komut:
- Verileri yÃ¼kler ve birleÅŸtirir
- Veriyi temizler
- Encoding ve normalizasyon yapar
- Korelasyon analizi yapar
- GÃ¶rselleÅŸtirmeleri oluÅŸturur
- Train/validation/test split oluÅŸturur
- Ä°ÅŸlenmiÅŸ veriyi kaydeder

#### AdÄ±m 2: Modelleme

```bash
python modeling.py
```

Bu komut:
- Geleneksel ML modellerini eÄŸitir
- Hiperparametre optimizasyonu yapar
- LSTM ve Bidirectional LSTM modellerini eÄŸitir
- Modelleri karÅŸÄ±laÅŸtÄ±rÄ±r
- Modelleri kaydeder

#### AdÄ±m 3: DeÄŸerlendirme

```bash
python evaluation.py
```

Veya `main.py` iÃ§inde otomatik olarak Ã§alÄ±ÅŸÄ±r.

#### AdÄ±m 4: Rapor OluÅŸturma

```bash
python reporting.py
```

Veya `main.py` iÃ§inde otomatik olarak Ã§alÄ±ÅŸÄ±r.

### YÃ¶ntem 3: GUI UygulamasÄ± (Streamlit)

```bash
streamlit run gui_app.py
```

Bu komut web tabanlÄ± bir arayÃ¼z aÃ§ar ve ÅŸunlarÄ± yapabilirsiniz:
- Veri yÃ¼kleme
- Veri Ã¶n iÅŸleme
- Model eÄŸitimi
- SonuÃ§larÄ± gÃ¶rÃ¼ntÃ¼leme
- Grafikleri inceleme

### SonuÃ§larÄ± Ä°nceleme

TÃ¼m sonuÃ§lar `results/` klasÃ¶rÃ¼nde bulunur:

- **GÃ¶rselleÅŸtirmeler**: `*.png` dosyalarÄ±
- **Ä°ÅŸlenmiÅŸ Veri**: `processed_data.csv`
- **Model KarÅŸÄ±laÅŸtÄ±rmasÄ±**: `model_comparison.csv` ve `model_comparison.png`
- **DeÄŸerlendirme Metrikleri**: `evaluation_metrics.csv` ve `metrics_comparison.png`
- **Confusion Matrix'ler**: `confusion_matrix_*.png`
- **Overfitting Analizi**: `overfitting_analysis.json` ve `overfitting_analysis_*.png`
- **EÄŸitilmiÅŸ Modeller**: `models/` klasÃ¶rÃ¼
- **En Ä°yi Model**: `models/best_model.*` ve `models/best_model_info.json`
- **Proje Raporu**: `project_report.html`

---

## ğŸ“ˆ SonuÃ§lar ve DeÄŸerlendirme

### Model Performans Metrikleri

Modeller aÅŸaÄŸÄ±daki metriklerle deÄŸerlendirilir:

1. **Accuracy**: Genel doÄŸruluk oranÄ±
2. **F1-Score**: Precision ve Recall'un dengeli Ã¶lÃ§Ã¼sÃ¼

### En Ä°yi Model SeÃ§imi

En iyi model, validation seti Ã¼zerindeki performansa gÃ¶re seÃ§ilir. Genellikle:
- **Derin Ã–ÄŸrenme Modelleri** (LSTM, Bidirectional LSTM): KarmaÅŸÄ±k pattern'leri yakalama
- **Random Forest (Optimized)**: Robust ve yorumlanabilir
- **SVM**: Non-linear iliÅŸkileri yakalama

---

## ğŸ” DetaylÄ± AÃ§Ä±klamalar

### Veri Ã–n Ä°ÅŸleme AdÄ±mlarÄ±

#### Eksik Veri Ä°ÅŸleme Stratejisi

- **Kategorik DeÄŸiÅŸkenler**: "Unknown" ile doldurulur
- **SayÄ±sal DeÄŸiÅŸkenler**: 0 ile doldurulur (normalizasyon sonrasÄ±)
- **Tarih**: GeÃ§ersiz tarihler NaN olarak bÄ±rakÄ±lÄ±r

#### AykÄ±rÄ± DeÄŸer Ä°ÅŸleme Stratejisi

- **YÃ¶ntem**: IQR (Interquartile Range)
- **Ä°ÅŸlem**: Silme yerine sÄ±nÄ±r deÄŸerleriyle deÄŸiÅŸtirme
- **Neden**: Veri kaybÄ±nÄ± Ã¶nlemek

#### Encoding Stratejisi

- **Label Encoding**: Kategorik deÄŸiÅŸkenler iÃ§in
- **One-Hot Encoding**: LSTM modelleri iÃ§in (categorical crossentropy loss)

#### Normalizasyon Stratejisi

- **StandardScaler**: Z-score normalizasyonu
- **Neden**: FarklÄ± Ã¶lÃ§eklerdeki deÄŸiÅŸkenleri aynÄ± Ã¶lÃ§eÄŸe getirmek

### Modelleme Stratejileri

#### Sequence Preparation (LSTM iÃ§in)

- **Sequence Length**: 10 (ayarlanabilir)
- **Padding**: KÄ±sa sequence'ler iÃ§in
- **One-Hot Encoding**: Ã‡ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma iÃ§in

#### Overfitting Ã–nleme

- **Dropout Layers**: %20-30 dropout
- **Early Stopping**: Validation loss izleme
- **Learning Rate Reduction**: Dinamik Ã¶ÄŸrenme oranÄ±

#### Model Kaydetme

- **Keras Modelleri**: `.h5` formatÄ±nda
- **Scikit-learn Modelleri**: `.pkl` formatÄ±nda (pickle)

---

## ğŸ“ Notlar

1. **Veri GizliliÄŸi**: Bu proje hassas veriler iÃ§ermektedir. Verilerin kullanÄ±mÄ±nda etik kurallara uyulmalÄ±dÄ±r.

2. **Performans**: BÃ¼yÃ¼k veri setleri iÃ§in model eÄŸitim sÃ¼releri uzun olabilir. GPU kullanÄ±mÄ± Ã¶nerilir.

3. **Hiperparametreler**: TÃ¼m hiperparametreler ayarlanabilir. Proje dosyalarÄ±ndaki ilgili bÃ¶lÃ¼mlerden deÄŸiÅŸtirilebilir.

4. **Encoding**: Label encoder'lar model kaydetme sÄ±rasÄ±nda saklanmalÄ±dÄ±r. Test verisi iÃ§in aynÄ± encoder'lar kullanÄ±lmalÄ±dÄ±r.

---

## ğŸ› ï¸ Sorun Giderme

### YaygÄ±n Hatalar

1. **Memory Error**: 
   - Batch size'Ä± kÃ¼Ã§Ã¼ltÃ¼n
   - Sequence length'i azaltÄ±n

2. **CUDA/GPU HatasÄ±**:
   - CPU moduna geÃ§in: TensorFlow otomatik olarak CPU kullanÄ±r

3. **Encoding HatasÄ±**:
   - Label encoder'larÄ±n doÄŸru yÃ¼klendiÄŸinden emin olun

---

## ğŸ“š Referanslar

- Scikit-learn Documentation: https://scikit-learn.org/
- TensorFlow Documentation: https://www.tensorflow.org/
- Pandas Documentation: https://pandas.pydata.org/
- Matplotlib Documentation: https://matplotlib.org/

---

## ğŸ‘¥ KatkÄ±da Bulunanlar

Bu proje DataMind-LSTM ekibi tarafÄ±ndan geliÅŸtirilmiÅŸtir.

---

## ğŸ“„ Lisans

Bu proje eÄŸitim amaÃ§lÄ±dÄ±r.

---

## ğŸ“ Ä°letiÅŸim

SorularÄ±nÄ±z iÃ§in issue aÃ§abilirsiniz.

---

**Son GÃ¼ncelleme**: 2024

